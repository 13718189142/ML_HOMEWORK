# ML_HOMEWORK
# TensoRF: åŸºäºå¼ é‡åˆ†è§£çš„ç¥ç»è¾å°„åœº

æœ¬é¡¹ç›®å®ç°äº†TensoRFï¼ˆTensor Radiance Fieldsï¼‰ç®—æ³•ï¼Œç”¨äº3Dåœºæ™¯é‡å»ºå’Œæ–°è§†è§’åˆæˆã€‚é€šè¿‡å¼ é‡åˆ†è§£æŠ€æœ¯ï¼ŒTensoRFèƒ½å¤Ÿé«˜æ•ˆåœ°è¡¨ç¤º3Dåœºæ™¯ï¼Œå®ç°é«˜è´¨é‡çš„ç¥ç»è¾å°„åœºæ¸²æŸ“ã€‚

## ğŸ“‹ ç›®å½•

- [é¡¹ç›®ç®€ä»‹](#é¡¹ç›®ç®€ä»‹)
- [ç¯å¢ƒè¦æ±‚](#ç¯å¢ƒè¦æ±‚)
- [å®‰è£…æŒ‡å—](#å®‰è£…æŒ‡å—)
- [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
- [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)
- [å®éªŒç»“æœ](#å®éªŒç»“æœ)
- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [å‚è€ƒæ–‡çŒ®](#å‚è€ƒæ–‡çŒ®)

## ğŸ¯ é¡¹ç›®ç®€ä»‹

TensoRFæ˜¯ä¸€ç§åŸºäºå¼ é‡åˆ†è§£çš„ç¥ç»è¾å°„åœºæ–¹æ³•ï¼Œç›¸æ¯”ä¼ ç»Ÿçš„NeRFå…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

- **é«˜æ•ˆè¡¨ç¤º**ï¼šä½¿ç”¨å¼ é‡åˆ†è§£æŠ€æœ¯ï¼Œå¤§å¹…å‡å°‘å†…å­˜å ç”¨
- **å¿«é€Ÿè®­ç»ƒ**ï¼šè®­ç»ƒé€Ÿåº¦æ¯”ä¼ ç»ŸNeRFå¿«10-100å€
- **é«˜è´¨é‡æ¸²æŸ“**ï¼šä¿æŒä¸NeRFç›¸å½“çš„æ¸²æŸ“è´¨é‡
- **çµæ´»é…ç½®**ï¼šæ”¯æŒå¤šç§æ•°æ®é›†å’Œåœºæ™¯ç±»å‹

## ğŸ”§ ç¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 1.8+
- CUDA 11.0+ (æ¨è)
- å…¶ä»–ä¾èµ–åŒ…è§ `requirements.txt`

### æ¨èé…ç½®
- GPU: NVIDIA RTX 3080 æˆ–æ›´é«˜
- å†…å­˜: 16GB+
- å­˜å‚¨: 50GB+ å¯ç”¨ç©ºé—´

## ğŸ“¦ å®‰è£…æŒ‡å—

1. **å…‹éš†é¡¹ç›®**
```bash
git clone <repository-url>
cd TensoRF-main
```

2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**
```bash
conda create -n tensorf python=3.8
conda activate tensorf
```

3. **å®‰è£…ä¾èµ–**
```bash
pip install -r requirements.txt
```

4. **éªŒè¯å®‰è£…**
```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

## ğŸ“ æ•°æ®å‡†å¤‡

### æ”¯æŒçš„æ•°æ®é›†

1. **NeRF Synthetic** (æ¨èç”¨äºæµ‹è¯•)
   - åŒ…å«: lego, ship, mic, chair, drums, ficus, hotdog, materials
   - ä¸‹è½½: [NeRF Synthetic Dataset](https://drive.google.com/drive/folders/128yBriW1IG_3NJ5Rp7APSTZNJQSlX9a1)

2. **LLFF (Local Light Field Fusion)**
   - åŒ…å«: fern, flower, room, leaves, horns, trex, fortress, orchids
   - ä¸‹è½½: [LLFF Dataset](https://drive.google.com/drive/folders/14boI-o5hGO9srnWaaogTU5_ji7wkX2S7)

3. **è‡ªå®šä¹‰æ•°æ®**
   - æ”¯æŒCOLMAPæ ¼å¼çš„ç›¸æœºå‚æ•°
   - å‚è€ƒ `dataLoader/your_own_data.py`

### æ•°æ®ç»„ç»‡ç»“æ„
```
data/
â”œâ”€â”€ nerf_synthetic/
â”‚   â””â”€â”€ lego/
â”‚       â”œâ”€â”€ train/
â”‚       â”œâ”€â”€ test/
â”‚       â”œâ”€â”€ val/
â”‚       â”œâ”€â”€ transforms_train.json
â”‚       â”œâ”€â”€ transforms_test.json
â”‚       â””â”€â”€ transforms_val.json
â””â”€â”€ nerf_llff_data/
    â””â”€â”€ fern/
        â”œâ”€â”€ images/
        â”œâ”€â”€ poses_bounds.npy
        â””â”€â”€ ...
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. è®­ç»ƒæ¨¡å‹

#### åŸºæœ¬è®­ç»ƒå‘½ä»¤
```bash
# ä½¿ç”¨é…ç½®æ–‡ä»¶è®­ç»ƒ
python train.py --config configs/lego.txt

# è‡ªå®šä¹‰å‚æ•°è®­ç»ƒ
python train.py \
    --config configs/lego.txt \
    --n_iters 10000 \
    --batch_size 4096 \
    --lr_init 0.02
```

#### è®­ç»ƒå‚æ•°è¯´æ˜
- `--n_iters`: è®­ç»ƒè¿­ä»£æ¬¡æ•° (é»˜è®¤: 10000)
- `--batch_size`: æ‰¹å¤„ç†å¤§å° (é»˜è®¤: 4096)
- `--lr_init`: åˆå§‹å­¦ä¹ ç‡ (é»˜è®¤: 0.02)
- `--progress_refresh_rate`: è¿›åº¦æ˜¾ç¤ºé¢‘ç‡ (é»˜è®¤: 100)

#### è®­ç»ƒè¿‡ç¨‹ç›‘æ§
- è®­ç»ƒæ—¥å¿—ä¿å­˜åœ¨ `log/{expname}/`
- è®­ç»ƒæ›²çº¿å›¾è‡ªåŠ¨ç”Ÿæˆ
- TensorBoardæ”¯æŒ: `tensorboard --logdir=log/`

### 2. æµ‹è¯•å’Œæ¸²æŸ“

#### è¿è¡Œæµ‹è¯•è„šæœ¬
```bash
# åŸºæœ¬æµ‹è¯•
python test_and_render.py --config configs/lego.txt

# æŒ‡å®šæ¨¡å‹æ–‡ä»¶
python test_and_render.py \
    --config configs/lego.txt \
    --ckpt log/tensorf_lego_VM/tensorf_lego_VM.th

# è‡ªå®šä¹‰æ¸²æŸ“å‚æ•°
python test_and_render.py \
    --config configs/lego.txt \
    --radius 4.0 \
    --num_views 180 \
    --n_samples 2048
```

#### æµ‹è¯•å‚æ•°è¯´æ˜
- `--ckpt`: æ¨¡å‹æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
- `--radius`: ç¯ç»•è½¨è¿¹åŠå¾„ (é»˜è®¤: 3.0)
- `--num_views`: ç¯ç»•è§†è§’æ•°é‡ (é»˜è®¤: 120)
- `--height`: ç›¸æœºé«˜åº¦ (é»˜è®¤: 1.2)
- `--n_samples`: é‡‡æ ·ç‚¹æ•° (é»˜è®¤: 1024)

### 3. å¯è§†åŒ–è®­ç»ƒæ›²çº¿

```bash
# ç”Ÿæˆè®­ç»ƒæ›²çº¿å›¾
python plot_training_curves.py
```

## ğŸ“Š å®éªŒç»“æœ

### æµ‹è¯•ç»“æœç¤ºä¾‹ (Legoæ•°æ®é›†)

| æŒ‡æ ‡ | æ•°å€¼ | è¯„ä»· |
|------|------|------|
| PSNR | 34.16 dB | ä¼˜ç§€ |
| SSIM | 0.9748 | æä¼˜ç§€ |
| LPIPS (Alex) | 0.0138 | æä¼˜ç§€ |
| LPIPS (VGG) | 0.0292 | æä¼˜ç§€ |

### æ€§èƒ½å¯¹æ¯”

| æ–¹æ³• | PSNR | è®­ç»ƒæ—¶é—´ | å†…å­˜å ç”¨ |
|------|------|----------|----------|
| NeRF | ~33 dB | 12-24å°æ—¶ | 8GB+ |
| **TensoRF** | **~34 dB** | **1-2å°æ—¶** | **2-4GB** |

## ğŸ“ é¡¹ç›®ç»“æ„

```
TensoRF-main/
â”œâ”€â”€ configs/                 # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ lego.txt            # Legoæ•°æ®é›†é…ç½®
â”‚   â”œâ”€â”€ flower.txt          # Floweræ•°æ®é›†é…ç½®
â”‚   â””â”€â”€ ...
â”œâ”€â”€ dataLoader/             # æ•°æ®åŠ è½½å™¨
â”‚   â”œâ”€â”€ blender.py          # NeRF Syntheticæ•°æ®é›†
â”‚   â”œâ”€â”€ llff.py             # LLFFæ•°æ®é›†
â”‚   â””â”€â”€ your_own_data.py    # è‡ªå®šä¹‰æ•°æ®
â”œâ”€â”€ models/                 # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ tensorBase.py       # åŸºç¡€å¼ é‡æ¨¡å‹
â”‚   â””â”€â”€ tensoRF.py          # TensoRFå®ç°
â”œâ”€â”€ log/                    # è®­ç»ƒæ—¥å¿—å’Œç»“æœ
â”‚   â””â”€â”€ tensorf_lego_VM/    # å®éªŒè¾“å‡º
â”œâ”€â”€ train.py                # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ test_and_render.py      # æµ‹è¯•å’Œæ¸²æŸ“è„šæœ¬
â”œâ”€â”€ plot_training_curves.py # è®­ç»ƒæ›²çº¿ç»˜åˆ¶
â””â”€â”€ README.md               # é¡¹ç›®è¯´æ˜
```

## âš™ï¸ é…ç½®è¯´æ˜

### ä¸»è¦é…ç½®å‚æ•°

```bash
# æ•°æ®é›†é…ç½®
dataset_name = blender          # æ•°æ®é›†ç±»å‹
datadir = ./data/nerf_synthetic/lego  # æ•°æ®è·¯å¾„

# è®­ç»ƒé…ç½®
n_iters = 10000                 # è®­ç»ƒè¿­ä»£æ¬¡æ•°
batch_size = 4096               # æ‰¹å¤„ç†å¤§å°
lr_init = 0.02                  # åˆå§‹å­¦ä¹ ç‡

# æ¨¡å‹é…ç½®
model_name = TensorVMSplit      # æ¨¡å‹ç±»å‹
N_voxel_init = 2097156          # åˆå§‹ä½“ç´ æ•° (128^3)
N_voxel_final = 27000000        # æœ€ç»ˆä½“ç´ æ•° (300^3)

# æ¸²æŸ“é…ç½®
N_vis = 5                       # å¯è§†åŒ–å›¾åƒæ•°é‡
vis_every = 5000                # å¯è§†åŒ–é¢‘ç‡
```

## ğŸ“ˆ è®­ç»ƒç›‘æ§

### å®æ—¶ç›‘æ§
```bash
# æŸ¥çœ‹è®­ç»ƒè¿›åº¦
tail -f log/tensorf_lego_VM/training_metrics.txt

# å¯åŠ¨TensorBoard
tensorboard --logdir=log/tensorf_lego_VM/
```

### å…³é”®æŒ‡æ ‡
- **PSNR**: å›¾åƒè´¨é‡æŒ‡æ ‡ï¼Œè¶Šé«˜è¶Šå¥½
- **Loss**: è®­ç»ƒæŸå¤±ï¼Œåº”è¯¥é€æ¸ä¸‹é™
- **Memory**: GPUå†…å­˜ä½¿ç”¨æƒ…å†µ

## ğŸ¬ è¾“å‡ºç»“æœ

### è®­ç»ƒå®Œæˆåä¼šç”Ÿæˆï¼š
1. **æ¨¡å‹æ–‡ä»¶**: `tensorf_lego_VM.th`
2. **è®­ç»ƒæ›²çº¿**: `training_curves_combined.png`
3. **æµ‹è¯•å›¾åƒ**: `test_results/`
4. **ç¯ç»•è§†é¢‘**: `render_path/video.mp4`
5. **æµ‹è¯•æŠ¥å‘Š**: `test_report.txt`

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. Chen, A., Xu, Z., Geiger, A., Yu, J., & Su, H. (2022). TensoRF: Tensorial Radiance Fields. In European Conference on Computer Vision (ECCV).

2. Mildenhall, B., Srinivasan, P. P., Tancik, M., Barron, J. T., Ramamoorthi, R., & Ng, R. (2020). NeRF: Representing scenes as neural radiance fields for view synthesis. In European Conference on Computer Vision (ECCV).
# NeRF-PyTorch ä¸­æ–‡è¯´æ˜

## nerf-pytorch-master
NeRF (Neural Radiance Fields) æ˜¯ä¸€ç§ç”¨äºæ–°è§†è§’åˆæˆçš„å…ˆè¿›æ–¹æ³•ã€‚æœ¬ä»“åº“æ˜¯ NeRF çš„ PyTorch å®ç°ï¼Œå¤ç°äº†åŸè®ºæ–‡ç»“æœä¸”è¿è¡Œé€Ÿåº¦æ›´å¿«ã€‚

## å®‰è£…
```bash
git clone https://github.com/yenchenlin/nerf-pytorch.git
cd nerf-pytorch
pip install -r requirements.txt
```

## å¼€å§‹

1. è®­ç»ƒæ¨¡å‹ï¼š
```bash
python run_nerf.py --config configs/lego.txt
```

2. æ¸²æŸ“æµ‹è¯•ï¼š
```bash
python run_nerf.py --config configs/lego.txt --render_only
```


# 3D Gaussian Splatting (3DGS)

## Table of Contents
1. [Deployment](#deployment)
2. [Training with Sample Data](#training-with-sample-data)
3. [Using Custom Data](#using-custom-data)
4. [Model Evaluation and Viewing](#model-evaluation-and-viewing)
5. [References](#references)

## Deployment

### Hardware Requirements
- **GPU**: NVIDIA GeForce RTX 4090 (or equivalent)

### Software Requirements
- **Operating System**: Windows 11
- **Python**: 3.10
- **CUDA Toolkit**: 12.3
- **PyTorch**: 2.2.1
- **Visual Studio**: 2022
- **Conda**: For environment management

### Installation Steps
1. Clone the repository with submodules:
   ```bash
   git clone https://github.com/graphdeco-inria/gaussian-splatting --recursive
   cd gaussian-splatting
   ```

2. Create and activate a Conda environment:
   ```bash
   conda create -n gaussian_splatting python=3.10
   conda activate gaussian_splatting
   ```

3. Install Visual Studio 2022:
   ```bash
   conda install -c conda-forge vs2022_win-64
   ```

4. Install PyTorch 2.2.1 with CUDA 12.1:
   ```bash
   pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
   ```

5. Set environment variable for Distutils:
   ```bash
   SET DISTUTILS_USE_SDK=1
   ```

6. Install required Python packages:
   ```bash
   pip install submodules\diff-gaussian-rasterization
   pip install submodules\simple-knn
   pip install plyfile
   pip install tqdm
   ```

## Training with Sample Data

### Data Download
Download the following dataset for training and evaluation:

- **Viewers for Windows (60MB)**: Compiled SIBR point cloud viewer tool.


### Training Process
Run the following command to start training:
```bash
python train.py -s <path to COLMAP or NeRF Synthetic dataset> --iterations <number of iterations>
```


### Viewing Training Process
Use the `SIBR_remoteGaussian_app` viewer to monitor the training process:
```bash
cd <path to viewers\bin>
.\SIBR_remoteGaussian_app.exe
```

## Using Custom Data

### Data Preparation
1. **Extract Frames from Video**:
   - Use `ffmpeg` to extract frames from a video:
     ```bash
     ffmpeg -i input.mp4 -vf "setpts=0.2*PTS" input/input_%4d.jpg
     ```
   - Download `ffmpeg` from [here](https://www.gyan.dev/ffmpeg/builds/).

2. **Convert Images Using COLMAP**:
   - Install COLMAP and add it to the system PATH.
   - Run the following command to convert images:
     ```bash
     colmap automatic_reconstructor --workspace_path . --image_path ./images --sparse 1 --camera_model SIMPLE_PINHOLE --dense 0
     ```

3. **Optional: Resize Images**:
   - Use ImageMagick for resizing images if necessary.

### Training with Custom Data
Follow the same training command as mentioned in the [Training with Sample Data](#training-with-sample-data) section.

## Model Evaluation and Viewing

### Model Output
Trained models are saved in the `output` folder (or a specified directory).

### Real-Time Viewer
Use the `SIBR_gaussianViewer_app` to view the trained point clouds:
```bash
cd <path to viewers\bin>
.\SIBR_gaussianViewer_app.exe -m <path to model folder>
```

### Evaluation
Save intermediate results during training:
```bash
python train.py -s <path to dataset> --eval
```

## References
- [3D Gaussian Splatting GitHub Repository](https://github.com/graphdeco-inria/gaussian-splatting)
- [COLMAP Repository](https://github.com/colmap/colmap)
- [ImageMagick](https://imagemagick.org/)
- [FFmpeg](https://www.ffmpeg.org/)
- [article on Zhihu](https://zhuanlan.zhihu.com/p/your-article-link).




